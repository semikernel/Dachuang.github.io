<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Manim Slides</title>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/reveal.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/theme/black.min.css">

    <!-- Theme used for syntax highlighting of code -->
    <!-- <link rel="stylesheet" href="lib/css/zenburn.css"> -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/zenburn.min.css">

    <!-- <link rel="stylesheet" href="index.css"> -->
  </head>

  <body>
    <div class="reveal">
      <div class="slides">
        <section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s00_5efa87ba1e09a2bdd4a386ae3509248cf4eec45098b21aa29437451e4f1cdd69.mp4"
          data-background-video-muted
          ><aside class="notes" data-markdown>各位老师、同学们，大家好！我是赵怡冰。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s00_db01c4579751c5896fda7c1ea699229c4b11ca1a4299d5154835e04dd93d340d.mp4"
          
          ><aside class="notes" data-markdown>各位老师、同学们，大家好！我是赵怡冰。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s01_0d258d6b434a7fc9c6eb08f051c56bec459e499f2a7cd7a901e30384889c4f44.mp4"
          
          ><aside class="notes" data-markdown>我们大创的题目是楼宇无人机自主安防布控系统设计与实现</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s01_c11db4e514b0d16b803e5b07497ae49d40cf0f88da81119313873f126b0b83c5.mp4"
          
          ><aside class="notes" data-markdown>我们大创的题目是楼宇无人机自主安防布控系统设计与实现</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s02_ed658a00986115af7a2a830d8e8cd1ee5d3744ce07e4875b62f0f9b335d99329.mp4"
          
          ><aside class="notes" data-markdown>我们答辩围绕研究背景，可应用场景，研究方法，研究过程和项目成果五个部分展开。首先是研究背景：</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s02_1ae734670a7d7b96c7097a9ece18dcb627f2463a05ab65332d2bc0f50cd6c312.mp4"
          
          ><aside class="notes" data-markdown>我们答辩围绕研究背景，可应用场景，研究方法，研究过程和项目成果五个部分展开。首先是研究背景：</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s02_d373964368a228df27bdf609484beac5534ac01bfc08c12241b4653c66f806de.mp4"
          
          ><aside class="notes" data-markdown>我们答辩围绕研究背景，可应用场景，研究方法，研究过程和项目成果五个部分展开。首先是研究背景：</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s03_6803e2e687627cd3cb5d1e797eb1b45529ffa8319c3b881a31280da05256518f.mp4"
          
          ><aside class="notes" data-markdown>这是位于中国深圳的腾讯总部大厦————滨海大厦。占地18650平方米，总投资18亿元。白天，这里有超过12000人办公，而到了夜间，这里的数据中心，各个出入口等风险部位都设置了安防系统。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s03_1e918cdf5c0a5965dbb00196d298473bb20ba68c88be2d747c436cd48ef5a281.mp4"
          
          ><aside class="notes" data-markdown>这是位于中国深圳的腾讯总部大厦————滨海大厦。占地18650平方米，总投资18亿元。白天，这里有超过12000人办公，而到了夜间，这里的数据中心，各个出入口等风险部位都设置了安防系统。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s04_58dd4c85b60042081d33fb94668cc73b436d62a4ee1fa8268914013469f2b385.mp4"
          
          ><aside class="notes" data-markdown>下面是可应用场景</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s04_d9306b47f36c1b0f6fb518703a90510e5b86c66abc95bcf22554fcc19278ab6f.mp4"
          
          ><aside class="notes" data-markdown>下面是可应用场景</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s05_37126ed42cfb25df268493725049552ae9e142376180f9aa2b95dc016ba83303.mp4"
          
          ><aside class="notes" data-markdown>现实中的安防系统远比我们想象中的复杂。不仅包括各种摄像头， 还包括红外探测器、玻璃破碎探测器、拾音器以及安防数据中心等等</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s05_a9c0e057b25388aae8b80554b9ab66789365eeba163863fcbe86181d6f5bd730.mp4"
          
          ><aside class="notes" data-markdown>现实中的安防系统远比我们想象中的复杂。不仅包括各种摄像头， 还包括红外探测器、玻璃破碎探测器、拾音器以及安防数据中心等等</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s05_e7ecb2a2d498e0b8688ff9a5208c4b29b7d82bfe99cc348d589dc28182d48d63.mp4"
          
          ><aside class="notes" data-markdown>现实中的安防系统远比我们想象中的复杂。不仅包括各种摄像头， 还包括红外探测器、玻璃破碎探测器、拾音器以及安防数据中心等等</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s05_bc584ee7d949ed71c231c815029c3737aa8d2c3df7dd60bf1a9334d9c8a7a124.mp4"
          
          ><aside class="notes" data-markdown>现实中的安防系统远比我们想象中的复杂。不仅包括各种摄像头， 还包括红外探测器、玻璃破碎探测器、拾音器以及安防数据中心等等</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s06_4b5e753f3858c355f40714d62447bac080956a82233be6219295dd4aa75b3e6d.mp4"
          
          ><aside class="notes" data-markdown>- 无人机的灵活性和机动性使其成为安防系统的理想补充。它们能迅速响应，提供实时监视，并几乎可以到达任意监控盲点。
  - 多无人机协同作业，能够实现更广阔区域的连续监控。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s06_1f0c0dcd6d1e408a061ad69be98bb3d7699a86bfda78e8b75bdec72b1d335d3f.mp4"
          
          ><aside class="notes" data-markdown>- 无人机的灵活性和机动性使其成为安防系统的理想补充。它们能迅速响应，提供实时监视，并几乎可以到达任意监控盲点。
  - 多无人机协同作业，能够实现更广阔区域的连续监控。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s07_6335b489ccc7a8217991c69066c1fe04938eed86590bbc64dd0edb97119e980c.mp4"
          
          ><aside class="notes" data-markdown>随着人工智能的飞速发展，计算机视觉算法可以对场景进行深层次理解。无人机与AI的深度融合可以为安防体系提供高效智能的技术手段</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s07_534ca0bb17704b8afb41a21806e1854ec9acaa79cc403e18c1a8310563dbbaff.mp4"
          
          ><aside class="notes" data-markdown>随着人工智能的飞速发展，计算机视觉算法可以对场景进行深层次理解。无人机与AI的深度融合可以为安防体系提供高效智能的技术手段</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s08_0399584c2ceb8e081da4ed74c118c31c7a095b7a6fecbfdbf1a3bde2ba32ce5c.mp4"
          
          ><aside class="notes" data-markdown>我们的大创项目聚焦在无人机上布置视觉算法，为智能巡检和智慧安防提供了一种可行方案</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s08_b83cc4f8e0909cadf2132253e7cf23662f37908a668616944c2323deded3dcd8.mp4"
          
          ><aside class="notes" data-markdown>我们的大创项目聚焦在无人机上布置视觉算法，为智能巡检和智慧安防提供了一种可行方案</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s09_eeff0457598e1efdd277e1e465e36ad1708162f0dacdb2d7d6dd8f8894ecdee1.mp4"
          
          ><aside class="notes" data-markdown>接下来介绍研究方法</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s09_92a1c50116388d8a6487c99476b482228827e2f9108d9e31775bd7e8117b92f7.mp4"
          
          ><aside class="notes" data-markdown>接下来介绍研究方法</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s10_245fece19eaee69df690bf3c807484c2ae5e74ea52eff62460981285bb8c0af9.mp4"
          
          ><aside class="notes" data-markdown>我们使用的硬件平台是tello无人机,为了使其同时拥有水平和垂直视角，我们3D打印了反射镜模块。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s10_cabdf85f8da4ab05aff3f8d429a876302935e901c4790fc2982dd35922021069.mp4"
          
          ><aside class="notes" data-markdown>我们使用的硬件平台是tello无人机,为了使其同时拥有水平和垂直视角，我们3D打印了反射镜模块。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s10_8b2e7844c8a0c53ff63adc48fd19ae11283fa0c163491e980bd6d1fc9ba02883.mp4"
          
          ><aside class="notes" data-markdown>我们使用的硬件平台是tello无人机,为了使其同时拥有水平和垂直视角，我们3D打印了反射镜模块。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s11_73ef0c4243cba0bf55e2f41dda204b16675166e87309d652f665cb8089d5d518.mp4"
          
          ><aside class="notes" data-markdown>我们的研究是逐步深化的，从基于Adaboost算法的人脸检测，和Yolo深度学习实现人脸检测与识别，再到我们最终设计实现的轻量化算法，更加贴近实用场景。接下来将展示我们预期实现的效果</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s11_d81d60c619d3128b34b3adf00d0fd7892181380ae9285a050c4ab2ed9cfa361a.mp4"
          
          ><aside class="notes" data-markdown>我们的研究是逐步深化的，从基于Adaboost算法的人脸检测，和Yolo深度学习实现人脸检测与识别，再到我们最终设计实现的轻量化算法，更加贴近实用场景。接下来将展示我们预期实现的效果</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s11_478fd3d32fb783235d2abc69cbfee76abebca272017df02e5f3bd434ed808a9b.mp4"
          
          ><aside class="notes" data-markdown>我们的研究是逐步深化的，从基于Adaboost算法的人脸检测，和Yolo深度学习实现人脸检测与识别，再到我们最终设计实现的轻量化算法，更加贴近实用场景。接下来将展示我们预期实现的效果</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s12_aac897c5af6759e4dccf51333affb7e49a6a840d86d76e7ba93aebd75751c260.mp4"
          
          ><aside class="notes" data-markdown>我们构建了一个三维空间，设置了一个最简单的场景。根据我们的设计目标，无人机能够识别人像，并随着人像的移动而移动，实现无人机的追踪功能。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s13_237ad5e4380d9b0d2e33e1d5ef543a0390498a8c3d378e8f9e9fde972e1a9d02.mp4"
          
          ><aside class="notes" data-markdown>我们首先结合Adaboost算法和Haar特征实现了人脸检测</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s13_c169be722b6872735197b476e0cf81b23f70ea67cb552dca0547a7b0033e0d46.mp4"
          
          ><aside class="notes" data-markdown>我们首先结合Adaboost算法和Haar特征实现了人脸检测</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s14_3076971acf38ddc70afa81cc173bac68a0352da18d15f565821a4da3231ce7ef.mp4"
          
          ><aside class="notes" data-markdown>基于Haar特征可以实时检测到人脸所在区域，通过捕捉无人机返回的视频流中的人像部分，计算得出偏移量，并将控制代码通过PID调参后回传给无人机，可以实现无人机跟随的效果。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s14_1468c4411a153c48074da719c0a38b8df586432bd2da0d19df76becb93961897.mp4"
          
          ><aside class="notes" data-markdown>基于Haar特征可以实时检测到人脸所在区域，通过捕捉无人机返回的视频流中的人像部分，计算得出偏移量，并将控制代码通过PID调参后回传给无人机，可以实现无人机跟随的效果。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s14_16a2765cc8b17876ede8a2b3a16441c054c0f2750bb4d41825629efcb6ab3cce.mp4"
          
          ><aside class="notes" data-markdown>基于Haar特征可以实时检测到人脸所在区域，通过捕捉无人机返回的视频流中的人像部分，计算得出偏移量，并将控制代码通过PID调参后回传给无人机，可以实现无人机跟随的效果。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s15_e15a78fa3e42c172d7d5f788dbf1d393e662b2eebf9a8b5d4b82ac39b859c199.mp4"
          
          ><aside class="notes" data-markdown>这里是我们实际的演示视频。左上角为无人机视图，无人机将计算的人像区域面积与预定值进行比较，判断人像远离或靠近。通过计算人像与画面中心点的偏移量，调整机身的偏转角度。无人机借助实时图像处理，确保目标始终处于摄像头的视野范围内,实现了无人机跟随的预期效果。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s16_237ad5e4380d9b0d2e33e1d5ef543a0390498a8c3d378e8f9e9fde972e1a9d02.mp4"
          
          ><aside class="notes" data-markdown>由于AdaBoost分类器只能做人脸检测，不具备人脸识别的功能，我们选用Yolo模型将检测到的位置信息和识别的身份信息整合到同一个端到端的模型下</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s16_f54826982b20311b4ab49219d75b8b18ed43e651ec19a56edc1e6751b55e8382.mp4"
          
          ><aside class="notes" data-markdown>由于AdaBoost分类器只能做人脸检测，不具备人脸识别的功能，我们选用Yolo模型将检测到的位置信息和识别的身份信息整合到同一个端到端的模型下</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s17_63b8d87aba8cfec88a57fdbf9c414bca247aa5d35eea7f9e74f24af1c6b3e297.mp4"
          
          ><aside class="notes" data-markdown>Yolo是一种深度学习框架，经过连续的迭代更新，已经演进到了YoloV9</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s17_105d0dcb0e79192ed5a693663459575bde873531fadfe25919d1a7bf7855f2c7.mp4"
          
          ><aside class="notes" data-markdown>Yolo是一种深度学习框架，经过连续的迭代更新，已经演进到了YoloV9</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s18_66a27b16e93802da62cce6a9634ae99359df4f6af0c21c3bdd03e5112fbb6a76.mp4"
          
          ><aside class="notes" data-markdown>Yolo可以使用预训练好的图像数据集进行检测，如包含了超过100万个物体实例的微软COCO数据集。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s18_eb59247ad04297e694def43e9c51380d506cf38a6da6fe3a5a881ef1cb54f607.mp4"
          
          ><aside class="notes" data-markdown>Yolo可以使用预训练好的图像数据集进行检测，如包含了超过100万个物体实例的微软COCO数据集。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s18_6856fd090b41bb7b5bd1f8e29513035cb67103a33f7bd8b7de6b08f575a26e24.mp4"
          
          ><aside class="notes" data-markdown>Yolo可以使用预训练好的图像数据集进行检测，如包含了超过100万个物体实例的微软COCO数据集。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s19_656f3e313a95de6d474dc97930ec3cfb189489ba36deb7c5101a529f466da158.mp4"
          
          ><aside class="notes" data-markdown>我们在学校的多个地点进行拍摄，并在这里演示了使用预训练的模型检测人像的结果。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s20_03a637ef5b7f8b9b28336ef60810639890b081c70a390cde92c87ec4e226b65f.mp4"
          
          ><aside class="notes" data-markdown>除了使用预训练模型外，我们还通过对6000多张，包含目标类别的正样本进行标注，生成了训练所需文件，并将文件上传至算力云平台, 训练后，我们实现了用于人脸识别的新模型。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="white"
          data-background-video="report_assets/s21_6bebf494e09e5fa9f3aa2a59489f97368710500d62215227bcc265a0bea2620c.mp4"
          
          ><aside class="notes" data-markdown>这里展示的是，我们自己的YoLo模型在训练过程中的损失精度图，能够直观地监控模型训练的进度和效果。可以看到，随着训练的进行,精度在不断提高。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s22_6da9aac9a20aad8d846b7d38570ce124502061ee599ef2e740335f28fc52c189.mp4"
          
          ><aside class="notes" data-markdown>这是我们实际的演示效果图，Yolo正确地识别到了指定人像。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s23_71ecf25fd557076825ad93b40d1781bf2a540c44fad2b6271e63f72009e62dff.mp4"
          
          ><aside class="notes" data-markdown>然而，训练YOLO模型需要大量的数据标注和计算资源，即使我们使用了NVIDIA的4090GPU，完成一个单一类的模型训练仍耗时55分钟之久。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s23_7d6bb7b30ef378ead0bf5a83ccd6c8f678ced94715a2faba3bfef5192cff4938.mp4"
          
          ><aside class="notes" data-markdown>然而，训练YOLO模型需要大量的数据标注和计算资源，即使我们使用了NVIDIA的4090GPU，完成一个单一类的模型训练仍耗时55分钟之久。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s24_7f2db5839378735e3049cb00f7c07c7630ed2d33958c4bc6505de789aabb642d.mp4"
          
          ><aside class="notes" data-markdown>因此，我们设计实现了一种轻量化算法，具有多尺度且旋转鲁棒的特性，更贴近使用场景。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s24_041483bc0d6923340a7abff2e99dcef5ad29367185280439edfe3b585c1dd8f1.mp4"
          
          ><aside class="notes" data-markdown>因此，我们设计实现了一种轻量化算法，具有多尺度且旋转鲁棒的特性，更贴近使用场景。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s25_ff1f81e26c15d800a735f85bc247d4e5ab900c92de5f9f0c0f8a76ad1a25d944.mp4"
          
          ><aside class="notes" data-markdown>我们设计的轻量化算法参考了局部二进制模式(Local Binary Patterns),其计算简单,不需要借助GPU进行加速。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s26_bd911b2542de63395aae47d363e216a4fa65e7ea6d70b25ee50bf7c49b6dbe48.mp4"
          data-background-video-loop
          ><aside class="notes" data-markdown>在可用资源有限的情况下，不依赖于卷积神经网络的LBP算法也可以完成检测和识别任务</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s27_e33df47e097cf8b146407a1180ff08e5728202f1bd0f403058eedf3b45ed9406.mp4"
          
          ><aside class="notes" data-markdown>最后是项目成果展示，为了展示无人机楼宇安防的实际效果，我们前往知行大厦八楼进行模拟演示。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s27_b20a0bc974bb3f60830737c4fbf3083b6d1cdda7a6f76e7d60053c1b6d3df28e.mp4"
          
          ><aside class="notes" data-markdown>最后是我们的项目成果展示，我们的答辩到此结束，恳请批评指正。</aside>
        </section><section
          data-background-size='contain'
          data-background-color="black"
          data-background-video="report_assets/s28_696e348724dbcdd0dd30b9a7ec1c8f3bf81a003541424f1071244f43e57900c6.mp4"
          data-background-video-loop
          ><aside class="notes" data-markdown>项目成果</aside>
        </section></div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/reveal.min.js"></script>

    <!-- To include plugins, see: https://revealjs.com/plugins/ -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/plugin/markdown/markdown.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.1.0/plugin/notes/notes.min.js"></script><!-- <script src="index.js"></script> -->
    <script>
      Reveal.initialize({
        plugins: [ RevealMarkdown, RevealNotes ],
        // The "normal" size of the presentation, aspect ratio will
        // be preserved when the presentation is scaled to fit different
        // resolutions. Can be specified using percentage units.
        width: '100%',
        height: '100%',

        // Factor of the display size that should remain empty around
        // the content
        margin: 0.04,

        // Bounds for smallest/largest possible scale to apply to content
        minScale: 0.2,
        maxScale: 2.0,

        // Display presentation control arrows
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: false,

        // Display the page number of the current slide
        // - true:    Show slide number
        // - false:   Hide slide number
        //
        // Can optionally be set as a string that specifies the number formatting:
        // - "h.v":   Horizontal . vertical slide number (default)
        // - "h/v":   Horizontal / vertical slide number
        // - "c":   Flattened slide number
        // - "c/t":   Flattened slide number / total slides
        //
        // Alternatively, you can provide a function that returns the slide
        // number for the current slide. The function should take in a slide
        // object and return an array with one string [slideNumber] or
        // three strings [n1,delimiter,n2]. See #formatSlideNumber().
        slideNumber: false,

        // Can be used to limit the contexts in which the slide number appears
        // - "all":      Always show the slide number
        // - "print":    Only when printing to PDF
        // - "speaker":  Only in the speaker view
        showSlideNumber: 'all',

        // Use 1 based indexing for # links to match slide number (default is zero
        // based)
        hashOneBasedIndex: false,

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: false,

        // Enable support for jump-to-slide navigation shortcuts
        jumpToSlide: true,

        // Push each slide change to the browser history.  Implies `hash: true`
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Optional function that blocks keyboard events when retuning false
        //
        // If you set this to 'focused', we will only capture keyboard events
        // for embedded decks when they are in focus
        keyboardCondition: null,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Enable the slide overview mode
        overview: true,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // Changes the behavior of our navigation directions.
        //
        // "default"
        // Left/right arrow keys step between horizontal slides, up/down
        // arrow keys step between vertical slides. Space key steps through
        // all slides (both horizontal and vertical).
        //
        // "linear"
        // Removes the up/down arrows. Left/right arrows step through all
        // slides (both horizontal and vertical).
        //
        // "grid"
        // When this is enabled, stepping left/right from a vertical stack
        // to an adjacent vertical stack will land you at the same vertical
        // index.
        //
        // Consider a deck with six slides ordered in two vertical stacks:
        // 1.1    2.1
        // 1.2    2.2
        // 1.3    2.3
        //
        // If you're on slide 1.3 and navigate right, you will normally move
        // from 1.3 -> 2.1. If "grid" is used, the same navigation takes you
        // from 1.3 -> 2.3.
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the question-mark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autolaying embedded media (video/audio/iframe)
        // - null:   Media will only autoplay if data-autoplay is present
        // - true:   All media will autoplay, regardless of individual setting
        // - false:  No media will autoplay, regardless of individual setting
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes
        // - null:   Iframes with data-src AND data-preload will be loaded when within
        //           the viewDistance, iframes with only data-src will be loaded when visible
        // - true:   All iframes with data-src will be loaded when within the viewDistance
        // - false:  All iframes with data-src will be loaded only when visible
        preloadIframes: null,

        // Can be used to globally disable auto-animation
        autoAnimate: true,

        // Optionally provide a custom element matcher that will be
        // used to dictate which elements we can animate between.
        autoAnimateMatcher: null,

        // Default settings for our auto-animate transitions, can be
        // overridden per-slide or per-element via data arguments
        autoAnimateEasing: 'ease',
        autoAnimateDuration: 1.0,
        autoAnimateUnmatched: true,

        // CSS properties that can be auto-animated. Position & scale
        // is matched separately so there's no need to include styles
        // like top/right/bottom/left, width/height or margin.
        autoAnimateStyles: ['opacity', 'color', 'background-color', 'padding', 'font-size', 'line-height', 'letter-spacing', 'border-width', 'border-color', 'border-radius', 'outline', 'outline-offset'],

        // Controls automatic progression to the next slide
        // - 0:      Auto-sliding only happens if the data-autoslide HTML attribute
        //           is present on the current slide or fragment
        // - 1+:     All slides will progress automatically at the given interval
        // - false:  No auto-sliding, even if data-autoslide is present
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding (defaults to navigateNext)
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // Opens links in an iframe preview overlay
        // Add `data-preview-link` and `data-preview-link="false"` to customize each link
        // individually
        previewLinks: false,

        // Exposes the reveal.js API through window.postMessage
        postMessage: true,

        // Dispatches all reveal.js events to the parent window through postMessage
        postMessageEvents: false,

        // Focuses body when page changes visibility to ensure keyboard shortcuts work
        focusBodyOnPageVisibilityChange: true,

        // Transition style
        transition: 'none', // none/fade/slide/convex/concave/zoom

        // Transition speed
        transitionSpeed: 'default', // default/fast/slow

        // Transition style for full page slide backgrounds
        backgroundTransition: 'none', // none/fade/slide/convex/concave/zoom

        // The maximum number of pages a single slide can expand onto when printing
        // to PDF, unlimited by default
        pdfMaxPagesPerSlide: Number.POSITIVE_INFINITY,

        // Prints each fragment on a separate slide
        pdfSeparateFragments: true,

        // Offset used to reduce the height of content within exported PDF pages.
        // This exists to account for environment differences based on how you
        // print to PDF. CLI printing options, like phantomjs and wkpdf, can end
        // on precisely the total height of the document whereas in-browser
        // printing has to end one pixel before.
        pdfPageHeightOffset: -1,

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000
      });

      
    </script>

    
  </body>
</html>